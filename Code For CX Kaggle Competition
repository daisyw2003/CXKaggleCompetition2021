{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fa4548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:37.848315Z",
     "iopub.status.busy": "2021-12-04T07:34:37.847007Z",
     "iopub.status.idle": "2021-12-04T07:34:38.833823Z",
     "shell.execute_reply": "2021-12-04T07:34:38.832874Z",
     "shell.execute_reply.started": "2021-12-04T07:33:41.817726Z"
    },
    "papermill": {
     "duration": 1.006069,
     "end_time": "2021-12-04T07:34:38.834044",
     "exception": false,
     "start_time": "2021-12-04T07:34:37.827975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b33084",
   "metadata": {
    "papermill": {
     "duration": 0.014088,
     "end_time": "2021-12-04T07:34:38.864593",
     "exception": false,
     "start_time": "2021-12-04T07:34:38.850505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Below is the general workflow of this project but feel free to add more additional steps as you wish and you could also not follow this workflow and designing your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc02fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:38.900240Z",
     "iopub.status.busy": "2021-12-04T07:34:38.899499Z",
     "iopub.status.idle": "2021-12-04T07:34:38.954405Z",
     "shell.execute_reply": "2021-12-04T07:34:38.954954Z",
     "shell.execute_reply.started": "2021-12-04T07:33:41.825380Z"
    },
    "papermill": {
     "duration": 0.076206,
     "end_time": "2021-12-04T07:34:38.955205",
     "exception": false,
     "start_time": "2021-12-04T07:34:38.878999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading dataa\n",
    "train = pd.read_csv('../input/cx-kaggle-final-project-fall-2021/train_datalabel.csv')\n",
    "test = pd.read_csv('../input/cx-kaggle-final-project-fall-2021/test_data.csv')\n",
    "submission = pd.read_csv('../input/cx-kaggle-final-project-fall-2021/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a98feab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:38.988355Z",
     "iopub.status.busy": "2021-12-04T07:34:38.987591Z",
     "iopub.status.idle": "2021-12-04T07:34:39.007871Z",
     "shell.execute_reply": "2021-12-04T07:34:39.008439Z",
     "shell.execute_reply.started": "2021-12-04T07:33:41.863233Z"
    },
    "papermill": {
     "duration": 0.038525,
     "end_time": "2021-12-04T07:34:39.008665",
     "exception": false,
     "start_time": "2021-12-04T07:34:38.970140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check if there exists N/A values in the dataframes here.\n",
    "train[train.isna().any(axis=1)] #157 null values out of 4088 (3%), all in BMI \n",
    "test[test.isna().any(axis=1)] #44 null values out of 1022 (4%), all in BMI\n",
    "\n",
    "#Think about how you could handing missing values.\n",
    "\n",
    "#Modify the dataframe here as you see fit.\n",
    "#Remove null values, they're only 3% and 4% of the data\n",
    "\n",
    "#train = train.dropna()\n",
    "#train = train.reset_index(drop=True)\n",
    "\n",
    "#test = test.dropna()\n",
    "#test = test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#coming back from the end. I need 1022 values for test. So I can't really drop. I'kk just grab the average BMI\n",
    "#and replace it (there's not much difference between genders either)\n",
    "train['bmi'].fillna(28.93,inplace=True)\n",
    "test['bmi'].fillna(28.74,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f20546b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.041861Z",
     "iopub.status.busy": "2021-12-04T07:34:39.040991Z",
     "iopub.status.idle": "2021-12-04T07:34:39.157161Z",
     "shell.execute_reply": "2021-12-04T07:34:39.156480Z",
     "shell.execute_reply.started": "2021-12-04T07:33:41.879900Z"
    },
    "papermill": {
     "duration": 0.134466,
     "end_time": "2021-12-04T07:34:39.157342",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.022876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Since there are categorical variables here, do can apply one hot encoding to categorical columns!\n",
    "#You can also use other techniques too if you wish.\n",
    "#REMEMBER TO APPLY THE SAME TRANSFORMATION TO BOTH TRAINING AND TESTDATA.\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    \n",
    "    #rural = 0, urban =1\n",
    "    df = df.replace(\"Urban\", 1)\n",
    "    df = df.replace(\"Rural\", 0)\n",
    "    \n",
    "    #married = 1, not_married =0\n",
    "    df = df.replace(\"Yes\", 1)\n",
    "    df = df.replace(\"No\", 0)\n",
    "    \n",
    "    #female = 1, male =0\n",
    "    df = df.replace(\"Female\", 1)\n",
    "    df = df.replace(\"Male\", 0)\n",
    "    \n",
    "    #smoking - make 4 columns for formerly smoked, never smoked, unknown, smokes\n",
    "    SS = df[[\"smoking_status\"]]\n",
    "    \n",
    "    #1 is formerly smoked\n",
    "    former = SS.replace(\"formerly smoked\", 1)\n",
    "    former = former.replace([\"never smoked\", \"smokes\", \"Unknown\"],0)\n",
    "    df = df.assign(formerly_smoked = former.values)\n",
    "    \n",
    "    #2 is Never smoked\n",
    "    never = SS.replace(\"never smoked\", 1)\n",
    "    never = never.replace([\"formerly smoked\", \"smokes\", \"Unknown\"],0)\n",
    "    df = df.assign(never_smoked = never.values)\n",
    "    \n",
    "    #3 is smokes\n",
    "    smokes = SS.replace(\"smokes\", 1)\n",
    "    smokes = smokes.replace([\"never smoked\", \"formerly smoked\", \"Unknown\"],0)\n",
    "    df = df.assign(smokes = smokes.values)\n",
    "    \n",
    "    #4 is unkown \n",
    "    unknown = SS.replace(\"Unknown\", 1)\n",
    "    unknown = unknown.replace([\"never smoked\", \"smokes\", \"formerly smoked\"],0)\n",
    "    df = df.assign(unknown_smoking = unknown.values)\n",
    "    \n",
    "    #remove the smoking_status column\n",
    "    df = df.drop('smoking_status', axis='columns')\n",
    "\n",
    "    \n",
    "    \n",
    "    #now moving onto work type Private, Self-employed, children, Govt_job, Never_worked\n",
    "    WT = df[[\"work_type\"]]\n",
    "    \n",
    "    #1 is Private\n",
    "    Private = WT.replace(\"Private\", 1)\n",
    "    Private = Private.replace([\"Self-employed\", \"children\", \"Govt_job\", \"Never_worked\"],0)\n",
    "    df = df.assign(Private_Work = Private.values)\n",
    "    \n",
    "    #2 is Self-employed\n",
    "    SE = WT.replace(\"Self-employed\", 1)\n",
    "    SE = SE.replace([\"Private\", \"children\", \"Govt_job\", \"Never_worked\"],0)\n",
    "    df = df.assign(Self_Employed = SE.values)\n",
    "    \n",
    "    #3 is children\n",
    "    Child = WT.replace(\"children\", 1)\n",
    "    Child = Private.replace([\"Self-employed\", \"Private\", \"Govt_job\", \"Never_worked\"],0)\n",
    "    df = df.assign(Children = Child.values)\n",
    "    \n",
    "    #4 is Govt_job\n",
    "    Gov = WT.replace(\"Govt_job\", 1)\n",
    "    Gov = Gov.replace([\"Self-employed\", \"Private\", \"children\", \"Never_worked\"],0)\n",
    "    df = df.assign(Government_Job = Gov.values)\n",
    "    \n",
    "    #5 is Never_worked\n",
    "    NW = WT.replace(\"Private\", 1)\n",
    "    NW = NW.replace([\"Self-employed\", \"children\", \"Govt_job\", \"Private\"],0)\n",
    "    df = df.assign(Never_Worked = NW.values)\n",
    "    \n",
    "    #remove the work_type column\n",
    "    df = df.drop('work_type', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df\n",
    "train = one_hot_encode(train)\n",
    "test = one_hot_encode(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7314de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.196382Z",
     "iopub.status.busy": "2021-12-04T07:34:39.195553Z",
     "iopub.status.idle": "2021-12-04T07:34:39.206529Z",
     "shell.execute_reply": "2021-12-04T07:34:39.205874Z",
     "shell.execute_reply.started": "2021-12-04T07:33:41.991974Z"
    },
    "papermill": {
     "duration": 0.035049,
     "end_time": "2021-12-04T07:34:39.206692",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.171643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now all your columns are numerical, think about if you need all columns for your model.\n",
    "#Drop/keep all columns as you see fit and explain your reasoning using comments.\n",
    "\n",
    "#remove the columns related to work. I don't htink your job has to do with Strokes unless you work in\n",
    "#a mine or something which is not mentioned in the job descriptions so job types are basically useless\n",
    "train = train.drop(['Private_Work','Self_Employed','Children','Government_Job', 'Never_Worked'], axis='columns')\n",
    "test = test.drop(['Private_Work','Self_Employed','Children','Government_Job', 'Never_Worked'], axis='columns')\n",
    "\n",
    "#marriage also has littled to do with stroke i believe\n",
    "#marriage doesn't change your heart condition unless its like you married someone whose unhealthy as well\n",
    "#but thats not indicated in our marriage stats so that should be dropped\n",
    "train = train.drop(['ever_married'], axis='columns')\n",
    "test = test.drop(['ever_married'], axis='columns')\n",
    "\n",
    "#while residency type may seem like htere's not much to do with stroke, urban areas have more smog\n",
    "#and there have been studies that show that smog often leads to weaker hearts\n",
    "\n",
    "train = train.drop(['Residence_type'], axis='columns')\n",
    "test = test.drop(['Residence_type'], axis='columns')\n",
    "\n",
    "#remaining columns all have to do with heart and lungs and health which are all important factors to stroke\n",
    "#predictions and such\n",
    "\n",
    "train = train.drop(['gender'], axis='columns')\n",
    "test = test.drop(['gender'], axis='columns')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a2472d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.238870Z",
     "iopub.status.busy": "2021-12-04T07:34:39.238013Z",
     "iopub.status.idle": "2021-12-04T07:34:39.385259Z",
     "shell.execute_reply": "2021-12-04T07:34:39.384661Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.010593Z"
    },
    "papermill": {
     "duration": 0.164569,
     "end_time": "2021-12-04T07:34:39.385434",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.220865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Optinal: Scale your numerical columns as you wish. Some models perform better with scaled features.\n",
    "#there is one \"Other\" gender. I am goign to drop.\n",
    "#train = train.drop(train.index[train.loc[:,\"gender\"]==\"Other\"])\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    " \n",
    "std_scaler = MinMaxScaler()\n",
    "train_scaled= std_scaler.fit_transform(train.to_numpy())\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=[\"id\",\"age\",\"hypertension\",\"heart_disease\",\n",
    "                                                   \"avg_glucose_level\",\"bmi\",\"stroke\",\"formerly_smoked\",\n",
    "                                                   \"never_smoked\",\"smokes\",\"unknown_smoking\"])\n",
    "\n",
    "\n",
    "test_scaled= std_scaler.fit_transform(test.to_numpy())\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=[\"id\",\"age\",\"hypertension\",\"heart_disease\",\n",
    "                                                   \"avg_glucose_level\",\"bmi\",\"formerly_smoked\",\n",
    "                                                \"never_smoked\",\"smokes\",\"unknown_smoking\"])\n",
    "test = test_scaled\n",
    "train = train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea2f163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.422443Z",
     "iopub.status.busy": "2021-12-04T07:34:39.421458Z",
     "iopub.status.idle": "2021-12-04T07:34:39.424018Z",
     "shell.execute_reply": "2021-12-04T07:34:39.423410Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.025072Z"
    },
    "papermill": {
     "duration": 0.024454,
     "end_time": "2021-12-04T07:34:39.424193",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.399739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#somehow. the y in my first KFold is all 0 the first time I've been doing it, so I'm going to shuffle my train database\n",
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f2a462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.456448Z",
     "iopub.status.busy": "2021-12-04T07:34:39.455672Z",
     "iopub.status.idle": "2021-12-04T07:34:39.533879Z",
     "shell.execute_reply": "2021-12-04T07:34:39.533253Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.039255Z"
    },
    "papermill": {
     "duration": 0.095665,
     "end_time": "2021-12-04T07:34:39.534056",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.438391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setup kfold cross validation here. Choose a k value as you see fit.\n",
    "\n",
    "#according to this website: https://www.statology.org/k-fold-cross-validation/, i'm going to choose 5\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "\n",
    "#y is whether or not they had a stroke\n",
    "#x is all columns except stroke data\n",
    "#i would want to run my model through this for loop\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "p = 0\n",
    "while p<1:\n",
    "    train = train.sample(frac=1)\n",
    "    kf = KFold(n_splits=5)\n",
    "    X = np.array(train.drop(['stroke'], axis='columns'))\n",
    "    y = train['stroke'].values\n",
    "    i=0\n",
    "    for train_index, val_index in kf.split(X): #i know i could just loop the regression thing itself but i got sus results the first time so...\n",
    "        if i==0:\n",
    "            X_train = X[train_index]\n",
    "            X_val = X[val_index]\n",
    "            y_train = y[train_index]\n",
    "            if np.sum(y_train) == 0:\n",
    "                p = 0\n",
    "            y_val = y[val_index]\n",
    "            i = i+1\n",
    "        elif i==1:\n",
    "            X_train_1 = X[train_index]\n",
    "            X_val_1 = X[val_index]\n",
    "            y_train_1 = y[train_index]\n",
    "            if np.sum(y_train_1) == 0:\n",
    "                p = 0\n",
    "            y_val_1 = y[val_index]\n",
    "            i = i+1\n",
    "        elif i==2:\n",
    "            X_train_2 = X[train_index]\n",
    "            X_val_2 = X[val_index]\n",
    "            y_train_2 = y[train_index]\n",
    "            if np.sum(y_train_2) == 0:\n",
    "                p = 0\n",
    "            y_val_2 = y[val_index]\n",
    "            i = i+1\n",
    "        elif i==3:\n",
    "            X_train_3 = X[train_index]\n",
    "            X_val_3 = X[val_index]\n",
    "            y_train_3 = y[train_index]\n",
    "            if np.sum(y_train_3) == 0:\n",
    "                p = 0\n",
    "            y_val_3 = y[val_index]\n",
    "            i = i+1\n",
    "        else:\n",
    "            X_train_4 = X[train_index]\n",
    "            X_val_4 = X[val_index]\n",
    "            y_train_4 = y[train_index]\n",
    "            if np.sum(y_train_4) == 0:\n",
    "                p = 0\n",
    "            y_val_4 = y[val_index]\n",
    "            i = i+1\n",
    "        p=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c12cbe",
   "metadata": {
    "papermill": {
     "duration": 0.013935,
     "end_time": "2021-12-04T07:34:39.563372",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.549437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c8f63c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.597048Z",
     "iopub.status.busy": "2021-12-04T07:34:39.595838Z",
     "iopub.status.idle": "2021-12-04T07:34:39.914334Z",
     "shell.execute_reply": "2021-12-04T07:34:39.913707Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.059902Z"
    },
    "papermill": {
     "duration": 0.336389,
     "end_time": "2021-12-04T07:34:39.914519",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.578130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st set\n",
      "CNF Matrix: \n",
      "[[770   0]\n",
      " [ 48   0]]\n",
      "LR Score: \n",
      "0.941320293398533\n",
      "2nd set\n",
      "CNF Matrix: \n",
      "[[781   0]\n",
      " [ 37   0]]\n",
      "LR Score: \n",
      "0.9547677261613692\n",
      "3rd set\n",
      "CNF Matrix: \n",
      "[[771   0]\n",
      " [ 47   0]]\n",
      "LR Score: \n",
      "0.9425427872860636\n",
      "4th set\n",
      "CNF Matrix: \n",
      "[[791   0]\n",
      " [ 26   0]]\n",
      "LR Score: \n",
      "0.9681762545899633\n",
      "5th set\n",
      "CNF Matrix: \n",
      "[[775   0]\n",
      " [ 42   0]]\n",
      "LR Score: \n",
      "0.9485924112607099\n"
     ]
    }
   ],
   "source": [
    "#Choose and create a model here. \n",
    "#Train the model using training data\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#1st time round\n",
    "print(\"1st set\")\n",
    "log_reg = lr.fit(X_train, y_train) #fits our model based on the data\n",
    "y_val_pred = log_reg.predict(X_val)\n",
    "cnf_matrix = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "print(\"CNF Matrix: \")\n",
    "print(cnf_matrix)\n",
    "print(\"LR Score: \")\n",
    "print(lr.score(X_val, y_val))\n",
    "\n",
    "#2nd time round\n",
    "print(\"2nd set\")\n",
    "log_reg_1 = lr.fit(X_train_1, y_train_1) #fits our model based on the data\n",
    "y_val_pred_1 = log_reg.predict(X_val_1)\n",
    "cnf_matrix_1 = metrics.confusion_matrix(y_val_1, y_val_pred_1)\n",
    "print(\"CNF Matrix: \")\n",
    "print(cnf_matrix_1)\n",
    "print(\"LR Score: \")\n",
    "print(lr.score(X_val_1, y_val_1))\n",
    "\n",
    "#3rd time round\n",
    "print(\"3rd set\")\n",
    "log_reg_2 = lr.fit(X_train_2, y_train_2) #fits our model based on the data\n",
    "y_val_pred_2 = log_reg.predict(X_val_2)\n",
    "cnf_matrix_2 = metrics.confusion_matrix(y_val_2, y_val_pred_2)\n",
    "print(\"CNF Matrix: \")\n",
    "print(cnf_matrix_2)\n",
    "print(\"LR Score: \")\n",
    "print(lr.score(X_val_2, y_val_2))\n",
    "\n",
    "#4th time round\n",
    "print(\"4th set\")\n",
    "log_reg_3 = lr.fit(X_train_3, y_train_3) #fits our model based on the data\n",
    "y_val_pred_3 = log_reg.predict(X_val_3)\n",
    "cnf_matrix_3 = metrics.confusion_matrix(y_val_3, y_val_pred_3)\n",
    "print(\"CNF Matrix: \")\n",
    "print(cnf_matrix_3)\n",
    "print(\"LR Score: \")\n",
    "print(lr.score(X_val_3, y_val_3))\n",
    "\n",
    "#5th time round\n",
    "print(\"5th set\")\n",
    "log_reg_4 = lr.fit(X_train_4, y_train_4) #fits our model based on the data\n",
    "y_val_pred_4 = log_reg.predict(X_val_4)\n",
    "cnf_matrix_4 = metrics.confusion_matrix(y_val_4, y_val_pred_4)\n",
    "print(\"CNF Matrix: \")\n",
    "print(cnf_matrix_4)\n",
    "print(\"LR Score: \")\n",
    "print(lr.score(X_val_4, y_val_4))\n",
    "\n",
    "#after doing all that copying pasting i've come to realize that i get the same sus results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac1c41e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.950292Z",
     "iopub.status.busy": "2021-12-04T07:34:39.949503Z",
     "iopub.status.idle": "2021-12-04T07:34:39.952765Z",
     "shell.execute_reply": "2021-12-04T07:34:39.952162Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.139504Z"
    },
    "papermill": {
     "duration": 0.023379,
     "end_time": "2021-12-04T07:34:39.952946",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.929567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Measure the performance of your model on the validation set and report the error by printing out the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d66659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:39.995101Z",
     "iopub.status.busy": "2021-12-04T07:34:39.993732Z",
     "iopub.status.idle": "2021-12-04T07:34:40.001955Z",
     "shell.execute_reply": "2021-12-04T07:34:40.000953Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.146928Z"
    },
    "papermill": {
     "duration": 0.034596,
     "end_time": "2021-12-04T07:34:40.002246",
     "exception": false,
     "start_time": "2021-12-04T07:34:39.967650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n"
     ]
    }
   ],
   "source": [
    "#Predict test data labels using your model here. \n",
    "#Your output should be of length 1022\n",
    "print(\"Test Data\")\n",
    "test_predict = log_reg.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81063574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:40.074269Z",
     "iopub.status.busy": "2021-12-04T07:34:40.072937Z",
     "iopub.status.idle": "2021-12-04T07:34:40.104496Z",
     "shell.execute_reply": "2021-12-04T07:34:40.103493Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.165113Z"
    },
    "papermill": {
     "duration": 0.075352,
     "end_time": "2021-12-04T07:34:40.104773",
     "exception": false,
     "start_time": "2021-12-04T07:34:40.029421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  stroke\n",
       "0        0     0.0\n",
       "1        1     0.0\n",
       "2        2     0.0\n",
       "3        3     0.0\n",
       "4        4     0.0\n",
       "...    ...     ...\n",
       "1017  1017     0.0\n",
       "1018  1018     0.0\n",
       "1019  1019     0.0\n",
       "1020  1020     0.0\n",
       "1021  1021     0.0\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the stroke column of submission variable I definied above to your test predictions.\n",
    "submission['stroke'] = test_predict\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92267d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T07:34:40.144425Z",
     "iopub.status.busy": "2021-12-04T07:34:40.143386Z",
     "iopub.status.idle": "2021-12-04T07:34:40.152903Z",
     "shell.execute_reply": "2021-12-04T07:34:40.152206Z",
     "shell.execute_reply.started": "2021-12-04T07:33:42.192518Z"
    },
    "papermill": {
     "duration": 0.030199,
     "end_time": "2021-12-04T07:34:40.153064",
     "exception": false,
     "start_time": "2021-12-04T07:34:40.122865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Saving the csv file\n",
    "#You can download this file by going to the output folder on the right side of your screen. The csv is in /kaggle/working\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ad5f9",
   "metadata": {
    "papermill": {
     "duration": 0.015056,
     "end_time": "2021-12-04T07:34:40.183876",
     "exception": false,
     "start_time": "2021-12-04T07:34:40.168820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.516878,
   "end_time": "2021-12-04T07:34:41.212737",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-04T07:34:27.695859",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
